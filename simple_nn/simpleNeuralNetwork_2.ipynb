{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define list of dataset\n",
    "dir = '../dataset/'\n",
    "datasets = [file for file in Path(dir).glob('*.csv')]\n",
    "\n",
    "datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to load data\n",
    "def load_data(filename):\n",
    "    df = pd.read_csv(filename, header=None, encoding='utf-8').dropna()\n",
    "    df.columns = ['label', 'data']\n",
    "\n",
    "    # return X, y\n",
    "    return df['data'], df['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to create train val test split\n",
    "def split_dataset(X, y):\n",
    "    # train 7 : val 2 : test 1\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=7)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.33, random_state=7)\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to extract feature\n",
    "def extract_feature(vectorizer, X, X_train, X_val, X_test):\n",
    "    vectorizer.fit(X)\n",
    "\n",
    "    X_train_extract = vectorizer.transform(X_train).toarray()\n",
    "    X_val_extract = vectorizer.transform(X_val).toarray()\n",
    "    X_test_extract = vectorizer.transform(X_test).toarray()\n",
    "\n",
    "    print(X_train_extract.shape)\n",
    "    print(X_val_extract.shape)\n",
    "    print(X_test_extract.shape)\n",
    "\n",
    "    return X_train_extract, X_val_extract, X_test_extract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to compile and train the model with given param\n",
    "def train_model(X_train, y_train, X_val, y_val, hidden_layer_size, activation_func, optimizer, learning_rate, epochs, batch_size, dropout=0):\n",
    "    keras.backend.clear_session()\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=hidden_layer_size, activation=activation_func, input_dim=X_train.shape[1]))\n",
    "\n",
    "    if dropout > 0:\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    model.compile(optimizer=optimizer(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val), verbose=2)\n",
    "\n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelBlueprint:\n",
    "    def __init__(self, hidden_layer_size, activation_func, optimizer,  learning_rate, epochs, batch_size, dropout):\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.activation_func = activation_func\n",
    "        self.optimizer = optimizer\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def __str__(self):\n",
    "        str = f'hidden_layer_size: {self.hidden_layer_size}, activation_func: {self.activation_func}, optimizer: {self.optimizer}, '\n",
    "        str += f'learning_rate: {self.learning_rate}, epochs: {self.epochs}, batch_size: {self.batch_size}, dropout: {self.dropout}'\n",
    "\n",
    "        return str\n",
    "\n",
    "\n",
    "# Define a list of models\n",
    "hidden_layer_size_sample = [32, 64, 128]\n",
    "# activation_func_sample = ['relu', 'softmax', 'softplus', 'softsign', 'selu', 'elu']\n",
    "activation_func_sample = ['relu', 'softplus', 'softsign', 'selu', 'elu']\n",
    "optimizer_sample = [keras.optimizers.Adam, keras.optimizers.RMSprop]\n",
    "# learning_rate_sample = [0.00001, 0.0001, 0.001, 0.01]\n",
    "learning_rate_sample = [0.0001]\n",
    "# epochs_sample = [10, 15, 20]\n",
    "epochs_sample = [15]\n",
    "# batch_size_sample = [12, 24, 36, 48, 60]\n",
    "batch_size_sample = [36]\n",
    "dropout_sample = [0]\n",
    "# dropout_sample = [0.1, 0.2, 0.3, 0.4]\n",
    "\n",
    "hyper_params = list(itertools.product(hidden_layer_size_sample, activation_func_sample, optimizer_sample,\n",
    "                    learning_rate_sample, epochs_sample, batch_size_sample, dropout_sample))\n",
    "model_blueprints = [ModelBlueprint(hidden_layer_size, activation_func, optimizer,  learning_rate, epochs, batch_size, dropout)\n",
    "                    for hidden_layer_size, activation_func, optimizer,  learning_rate, epochs, batch_size, dropout in hyper_params]\n",
    "\n",
    "# Look at all combination of hyper_params we have\n",
    "print(len(model_blueprints))\n",
    "\n",
    "for m in model_blueprints:\n",
    "    print(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function loop all hypermeter and return the best\n",
    "def train_with_all_blueprints(X_train, y_train, X_val, y_val, model_blueprints):\n",
    "    models = []\n",
    "    histories = []\n",
    "\n",
    "    for i, blueprint in enumerate(model_blueprints):\n",
    "        print(f'{i}: {blueprint}')\n",
    "\n",
    "        model, history = train_model(X_train, y_train, X_val, y_val,\n",
    "                                     blueprint.hidden_layer_size, blueprint.activation_func, blueprint.optimizer, blueprint.learning_rate,\n",
    "                                     blueprint.epochs, blueprint.batch_size, blueprint.dropout)\n",
    "\n",
    "        models.append(model)\n",
    "        histories.append(history)\n",
    "\n",
    "    return models, histories\n",
    "\n",
    "\n",
    "def get_best_model(models, histories, model_blueprints):\n",
    "    best_val_acc_overall = 0\n",
    "    best_model_index = 0\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "        best_val_acc = max(model.history.history['val_accuracy'])\n",
    "\n",
    "        if (best_val_acc > best_val_acc_overall):\n",
    "            best_val_acc_overall = best_val_acc\n",
    "            best_model_index = i\n",
    "\n",
    "    return best_val_acc_overall, models[best_model_index], histories[best_model_index], model_blueprints[best_model_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for plot graph\n",
    "def plot_graphs(history,  dataset):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "    plt.suptitle(dataset)\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.suptitle(dataset)\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test each dataset with each combination of hyperparameter\n",
    "best_models = []\n",
    "\n",
    "for dataset in datasets:\n",
    "    X, y = load_data(dataset)\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = split_dataset(X, y)\n",
    "    X_train, X_val, X_test = extract_feature(CountVectorizer(), X, X_train, X_val, X_test)\n",
    "    models, histories = train_with_all_blueprints(X_train, y_train, X_val, y_val, model_blueprints)\n",
    "    val_accuracy, model, history, blueprint = get_best_model(models, histories, model_blueprints)\n",
    "    loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "    print(dataset)\n",
    "    print(blueprint)\n",
    "    print(f'Val accuracy: {val_accuracy}: Test accuracy: {test_accuracy}')\n",
    "\n",
    "    plot_graphs(history, dataset)\n",
    "\n",
    "    best_models.append(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the performance of the model\n",
    "def spamDetection(message):\n",
    "    vectorizer = HashingVectorizer(stop_words='english', n_features=5000)\n",
    "    inputMsg = vectorizer.fit_transform([message]).toarray()\n",
    "    return best_model.predict(inputMsg)\n",
    "\n",
    "\n",
    "# print(spamDetection(\"hey let grab lunch tgt next week shall we\"))\n",
    "# print(spamDetection(\"important email account has been hacked attention require click link to reset password\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "87dc40f78584ad215daf1a34029e7534cfef3110b38cfe89103d23fe1936177c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
