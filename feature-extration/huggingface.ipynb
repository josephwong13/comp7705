{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d635582a-0ab9-4abe-ba76-f69211f45e5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForMaskedLM.\n",
      "\n",
      "All the layers of TFBertForMaskedLM were initialized from the model checkpoint at bert-base-chinese.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForMaskedLM for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Hugging face testing\n",
    "from transformers import AutoTokenizer, TFAutoModelForMaskedLM\n",
    "import tensorflow as tf\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-chinese\")\n",
    "\n",
    "model = TFAutoModelForMaskedLM.from_pretrained(\"bert-base-chinese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e827372-8c9a-4561-b629-072a0866fbd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-5 predictions:\n",
      "爽: 0.6484012007713318\n",
      "新: 0.16201545298099518\n",
      "涼: 0.08563422411680222\n",
      "朗: 0.0348283126950264\n",
      "淨: 0.006423946004360914\n"
     ]
    }
   ],
   "source": [
    "# Define the input sentence with [MASK] token\n",
    "sms = \"今天的天氣很清[MASK]舒服\"\n",
    "\n",
    "# Tokenize the input sentence\n",
    "inputs = tokenizer(sms, return_tensors='tf')\n",
    "\n",
    "# Get the position of the [MASK] token\n",
    "mask_token_index = tf.where(inputs['input_ids'] == tokenizer.mask_token_id)[0, 1]\n",
    "\n",
    "# Generate model predictions for the masked token\n",
    "outputs = model(inputs['input_ids'], attention_mask=inputs['attention_mask'])\n",
    "predictions = outputs.logits[0, mask_token_index]\n",
    "\n",
    "# Convert the predictions to probabilities\n",
    "probabilities = tf.nn.softmax(predictions, axis=-1)\n",
    "\n",
    "# Get the top-k predicted tokens and their probabilities\n",
    "k = 5\n",
    "top_k_values, top_k_indices = tf.math.top_k(probabilities, k=k)\n",
    "predicted_tokens = tokenizer.convert_ids_to_tokens(top_k_indices.numpy())\n",
    "\n",
    "# Print the top-k predicted tokens and their probabilities\n",
    "print(f\"Top-{k} predictions:\")\n",
    "for i in range(k):\n",
    "    print(f\"{predicted_tokens[i]}: {top_k_values[i].numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6453bd6-9f59-4e71-97db-f1794030b6fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kernel_for_tensorflow",
   "language": "python",
   "name": "kernel_for_tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
